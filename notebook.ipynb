{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Linear Classifiers in Python\n",
                "\n",
                "## Applying logistic regression and SVM\n",
                "\n",
                "### KNN classification\n",
                "\n",
                "In this exercise you'll explore a subset of the [Large Movie Review\n",
                "Dataset](https://ai.stanford.edu/~amaas/data/sentiment/). The variables\n",
                "`X_train`, `X_test`, `y_train`, and `y_test` are already loaded into the\n",
                "environment. The `X` variables contain features based on the words in\n",
                "the movie reviews, and the `y` variables contain labels for whether the\n",
                "review sentiment is positive (+1) or negative (-1).\n",
                "\n",
                "*This course touches on a lot of concepts you may have forgotten, so if\n",
                "you ever need a quick refresher, download the [scikit-learn Cheat\n",
                "Sheet](https://www.datacamp.com/cheat-sheet/scikit-learn-cheat-sheet-python-machine-learning)\n",
                "and keep it handy!*\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Create a KNN model with default hyperparameters.\n",
                "- Fit the model.\n",
                "- Print out the prediction for the test example 0.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Defaulting to user installation because normal site-packages is not writeable\n",
                        "Requirement already satisfied: numpy in /home/vscode/.local/lib/python3.12/site-packages (1.26.4)\n",
                        "Requirement already satisfied: scikit-learn in /home/vscode/.local/lib/python3.12/site-packages (1.5.0)\n",
                        "Requirement already satisfied: scipy>=1.6.0 in /home/vscode/.local/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
                        "Requirement already satisfied: joblib>=1.2.0 in /home/vscode/.local/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
                        "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/vscode/.local/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
                        "Note: you may need to restart the kernel to use updated packages.\n"
                    ]
                }
            ],
            "source": [
                "pip install numpy scikit-learn"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [],
            "source": [
                "# added/edited\n",
                "import numpy as np\n",
                "from sklearn.datasets import load_svmlight_file\n",
                "X_train, y_train = load_svmlight_file('aclImdb/train/labeledBow.feat')\n",
                "X_test, y_test = load_svmlight_file('aclImdb/test/labeledBow.feat')\n",
                "y_train = np.where(y_train < 5, -1.0, 1.0)\n",
                "y_test = np.where(y_test < 5, -1.0, 1.0)\n",
                "X_train = X_train[:, :X_test.shape[1]]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Prediction for test example 0: -1.0\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "\n",
                "# Create and fit the model\n",
                "knn = KNeighborsClassifier()\n",
                "knn.fit(X_train, y_train)\n",
                "\n",
                "# Predict on the test features, print the results\n",
                "pred = knn.predict(X_test)[0]\n",
                "print(\"Prediction for test example 0:\", pred)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Running LogisticRegression and SVC\n",
                "\n",
                "In this exercise, you'll apply logistic regression and a support vector\n",
                "machine to classify images of handwritten digits.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Apply logistic regression and SVM (using `SVC()`) to the handwritten\n",
                "  digits data set using the provided train/validation split.\n",
                "- For each classifier, print out the training and validation accuracy.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [],
            "source": [
                "# added/edited\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.svm import SVC"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1.0\n",
                        "0.9644444444444444\n",
                        "0.9970304380103935\n",
                        "0.9888888888888889\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/vscode/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
                        "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
                        "\n",
                        "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
                        "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
                        "Please also refer to the documentation for alternative solver options:\n",
                        "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
                        "  n_iter_i = _check_optimize_result(\n"
                    ]
                }
            ],
            "source": [
                "from sklearn import datasets\n",
                "digits = datasets.load_digits()\n",
                "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target)\n",
                "\n",
                "# Apply logistic regression and print scores\n",
                "lr = LogisticRegression()\n",
                "lr.fit(X_train, y_train)\n",
                "print(lr.score(X_train, y_train))\n",
                "print(lr.score(X_test, y_test))\n",
                "\n",
                "# Apply SVM and print scores\n",
                "svm = SVC()\n",
                "svm.fit(X_train, y_train)\n",
                "print(svm.score(X_train, y_train))\n",
                "print(svm.score(X_test, y_test))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Sentiment analysis for movie reviews\n",
                "\n",
                "In this exercise you'll explore the probabilities outputted by logistic\n",
                "regression on a subset of the [Large Movie Review\n",
                "Dataset](https://ai.stanford.edu/~amaas/data/sentiment/).\n",
                "\n",
                "The variables `X` and `y` are already loaded into the environment. `X`\n",
                "contains features based on the number of times words appear in the movie\n",
                "reviews, and `y` contains labels for whether the review sentiment is\n",
                "positive (+1) or negative (-1).\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Train a logistic regression model on the movie review data.\n",
                "- Predict the probabilities of negative vs. positive for the two given\n",
                "  reviews.\n",
                "- Feel free to write your own reviews and get probabilities for those\n",
                "  too!\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Defaulting to user installation because normal site-packages is not writeable\n",
                        "Requirement already satisfied: pandas in /home/vscode/.local/lib/python3.12/site-packages (2.2.2)\n",
                        "Requirement already satisfied: numpy>=1.26.0 in /home/vscode/.local/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
                        "Requirement already satisfied: python-dateutil>=2.8.2 in /home/vscode/.local/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
                        "Requirement already satisfied: pytz>=2020.1 in /home/vscode/.local/lib/python3.12/site-packages (from pandas) (2024.1)\n",
                        "Requirement already satisfied: tzdata>=2022.7 in /home/vscode/.local/lib/python3.12/site-packages (from pandas) (2024.1)\n",
                        "Requirement already satisfied: six>=1.5 in /home/vscode/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
                        "Note: you may need to restart the kernel to use updated packages.\n"
                    ]
                }
            ],
            "source": [
                "pip install pandas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [],
            "source": [
                "# added/edited\n",
                "import numpy as np\n",
                "from sklearn.datasets import load_svmlight_file\n",
                "from sklearn.feature_extraction.text import CountVectorizer\n",
                "import pandas as pd\n",
                "vocabulary = pd.read_csv('./aclImdb/imdb.vocab', header=None, names=['word']).drop_duplicates()['word'].values\n",
                "\n",
                "X, y = load_svmlight_file('aclImdb/train/labeledBow.feat')\n",
                "y = np.where(y < 5, -1.0, 1.0)\n",
                "X = X[:, :len(vocabulary)]\n",
                "vectorizer = CountVectorizer(vocabulary=vocabulary)\n",
                "def get_features(review):\n",
                "    return vectorizer.transform([review])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Review: LOVED IT! This movie was amazing. Top 10 this year.\n",
                        "Probability of positive review: 0.9410706078385538\n",
                        "Review: Total junk! I'll never watch a film by that director again, no matter how good the reviews.\n",
                        "Probability of positive review: 0.210369701664537\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/vscode/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
                        "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
                        "\n",
                        "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
                        "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
                        "Please also refer to the documentation for alternative solver options:\n",
                        "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
                        "  n_iter_i = _check_optimize_result(\n"
                    ]
                }
            ],
            "source": [
                "# Instantiate logistic regression and train\n",
                "lr = LogisticRegression()\n",
                "lr.fit(X, y)\n",
                "\n",
                "# Predict sentiment for a glowing review\n",
                "review1 = \"LOVED IT! This movie was amazing. Top 10 this year.\"\n",
                "review1_features = get_features(review1)\n",
                "print(\"Review:\", review1)\n",
                "print(\"Probability of positive review:\", lr.predict_proba(review1_features)[0,1])\n",
                "\n",
                "# Predict sentiment for a poor review\n",
                "review2 = \"Total junk! I'll never watch a film by that director again, no matter how good the reviews.\"\n",
                "review2_features = get_features(review2)\n",
                "print(\"Review:\", review2)\n",
                "print(\"Probability of positive review:\", lr.predict_proba(review2_features)[0,1])\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Visualizing decision boundaries\n",
                "\n",
                "In this exercise, you'll visualize the decision boundaries of various\n",
                "classifier types.\n",
                "\n",
                "A subset of `scikit-learn`'s built-in `wine` dataset is already loaded\n",
                "into `X`, along with binary labels in `y`.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Create the following classifier objects with default hyperparameters:\n",
                "  `LogisticRegression`, `LinearSVC`, `SVC`, `KNeighborsClassifier`.\n",
                "- Fit each of the classifiers on the provided data using a `for` loop.\n",
                "- Call the `plot_4_classifers()` function (similar to the code\n",
                "  [here](https://scikit-learn.org/stable/auto_examples/svm/plot_iris_svc.html)),\n",
                "  passing in `X`, `y`, and a list containing the four classifiers.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Defaulting to user installation because normal site-packages is not writeable\n",
                        "Requirement already satisfied: matplotlib in /home/vscode/.local/lib/python3.12/site-packages (3.9.0)\n",
                        "Requirement already satisfied: contourpy>=1.0.1 in /home/vscode/.local/lib/python3.12/site-packages (from matplotlib) (1.2.1)\n",
                        "Requirement already satisfied: cycler>=0.10 in /home/vscode/.local/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
                        "Requirement already satisfied: fonttools>=4.22.0 in /home/vscode/.local/lib/python3.12/site-packages (from matplotlib) (4.53.0)\n",
                        "Requirement already satisfied: kiwisolver>=1.3.1 in /home/vscode/.local/lib/python3.12/site-packages (from matplotlib) (1.4.5)\n",
                        "Requirement already satisfied: numpy>=1.23 in /home/vscode/.local/lib/python3.12/site-packages (from matplotlib) (1.26.4)\n",
                        "Requirement already satisfied: packaging>=20.0 in /home/vscode/.local/lib/python3.12/site-packages (from matplotlib) (24.0)\n",
                        "Requirement already satisfied: pillow>=8 in /home/vscode/.local/lib/python3.12/site-packages (from matplotlib) (10.3.0)\n",
                        "Requirement already satisfied: pyparsing>=2.3.1 in /home/vscode/.local/lib/python3.12/site-packages (from matplotlib) (3.1.2)\n",
                        "Requirement already satisfied: python-dateutil>=2.7 in /home/vscode/.local/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
                        "Requirement already satisfied: six>=1.5 in /home/vscode/.local/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
                        "Note: you may need to restart the kernel to use updated packages.\n"
                    ]
                }
            ],
            "source": [
                "pip install matplotlib"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [],
            "source": [
                "# added/edited\n",
                "import matplotlib.pyplot as plt \n",
                "X = np.array([[11.45,  2.4 ], [13.62,  4.95], [13.88,  1.89], [12.42,  2.55], [12.81,  2.31], [12.58,  1.29], [13.83,  1.57], [13.07,  1.5 ], [12.7 ,  3.55], [13.77,  1.9 ], [12.84,  2.96], [12.37,  1.63], [13.51,  1.8 ], [13.87,  1.9 ], [12.08,  1.39], [13.58,  1.66], [13.08,  3.9 ], [11.79,  2.13], [12.45,  3.03], [13.68,  1.83], [13.52,  3.17], [13.5 ,  3.12], [12.87,  4.61], [14.02,  1.68], [12.29,  3.17], [12.08,  1.13], [12.7 ,  3.87], [11.03,  1.51], [13.32,  3.24], [14.13,  4.1 ], [13.49,  1.66], [11.84,  2.89], [13.05,  2.05], [12.72,  1.81], [12.82,  3.37], [13.4 ,  4.6 ], [14.22,  3.99], [13.72,  1.43], [12.93,  2.81], [11.64,  2.06], [12.29,  1.61], [11.65,  1.67], [13.28,  1.64], [12.93,  3.8 ], [13.86,  1.35], [11.82,  1.72], [12.37,  1.17], [12.42,  1.61], [13.9 ,  1.68], [14.16,  2.51]])\n",
                "y = np.array([ True,  True, False,  True,  True,  True, False, False,  True, False,  True,  True, False, False,  True, False,  True,  True, True, False,  True,  True,  True, False,  True,  True,  True, True,  True,  True,  True,  True, False,  True,  True,  True, False, False,  True,  True,  True,  True, False, False, False, True,  True,  True, False,  True])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "<>:66: SyntaxWarning: invalid escape sequence '\\D'\n",
                        "<>:66: SyntaxWarning: invalid escape sequence '\\D'\n",
                        "/tmp/ipykernel_14591/3944463996.py:66: SyntaxWarning: invalid escape sequence '\\D'\n",
                        "  cbar.ax.set_ylabel('probability of red $\\Delta$ class', fontsize=20, rotation=270, labelpad=30)\n"
                    ]
                }
            ],
            "source": [
                "# added/edited\n",
                "def make_meshgrid(x, y, h=.02, lims=None):\n",
                "    \"\"\"Create a mesh of points to plot in\n",
                "    \n",
                "    Parameters\n",
                "    ----------\n",
                "        x: data to base x-axis meshgrid on\n",
                "        y: data to base y-axis meshgrid on\n",
                "        h: stepsize for meshgrid, optional\n",
                "        \n",
                "    Returns\n",
                "    -------\n",
                "        xx, yy : ndarray\n",
                "    \"\"\"\n",
                "    \n",
                "    if lims is None:\n",
                "        x_min, x_max = x.min() - 1, x.max() + 1\n",
                "        y_min, y_max = y.min() - 1, y.max() + 1\n",
                "    else:\n",
                "        x_min, x_max, y_min, y_max = lims\n",
                "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
                "                         np.arange(y_min, y_max, h))\n",
                "    return xx, yy\n",
                "\n",
                "\n",
                "def plot_contours(ax, clf, xx, yy, proba=False, **params):\n",
                "    \"\"\"Plot the decision boundaries for a classifier.\n",
                "    \n",
                "    Parameters\n",
                "    ----------\n",
                "        ax: matplotlib axes object\n",
                "        clf: a classifier\n",
                "        xx: meshgrid ndarray\n",
                "        yy: meshgrid ndarray\n",
                "        params: dictionary of params to pass to contourf, optional\n",
                "    \"\"\"\n",
                "    if proba:\n",
                "        Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:,-1]\n",
                "        Z = Z.reshape(xx.shape)\n",
                "        out = ax.imshow(Z,extent=(np.min(xx), np.max(xx), np.min(yy), np.max(yy)), \n",
                "                        origin='lower', vmin=0, vmax=1, **params)\n",
                "        ax.contour(xx, yy, Z, levels=[0.5])\n",
                "    else:\n",
                "        Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
                "        Z = Z.reshape(xx.shape)\n",
                "        out = ax.contourf(xx, yy, Z, **params)\n",
                "    return out\n",
                "\n",
                "\n",
                "def plot_classifier(X, y, clf, ax=None, ticks=False, proba=False, lims=None): \n",
                "    # assumes classifier \"clf\" is already fit\n",
                "    X0, X1 = X[:, 0], X[:, 1]\n",
                "    xx, yy = make_meshgrid(X0, X1, lims=lims)\n",
                "    \n",
                "    if ax is None:\n",
                "        plt.figure()\n",
                "        ax = plt.gca()\n",
                "        show = True\n",
                "    else:\n",
                "        show = False\n",
                "        \n",
                "    # can abstract some of this into a higher-level function for learners to call\n",
                "    cs = plot_contours(ax, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8, proba=proba)\n",
                "    if proba:\n",
                "        cbar = plt.colorbar(cs)\n",
                "        cbar.ax.set_ylabel('probability of red $\\Delta$ class', fontsize=20, rotation=270, labelpad=30)\n",
                "        cbar.ax.tick_params(labelsize=14)\n",
                "        #ax.scatter(X0, X1, c=y, cmap=plt.cm.coolwarm, s=30, edgecolors=\\'k\\', linewidth=1)\n",
                "    labels = np.unique(y)\n",
                "    if len(labels) == 2:\n",
                "        ax.scatter(X0[y==labels[0]], X1[y==labels[0]], cmap=plt.cm.coolwarm, \n",
                "                   s=60, c='b', marker='o', edgecolors='k')\n",
                "        ax.scatter(X0[y==labels[1]], X1[y==labels[1]], cmap=plt.cm.coolwarm, \n",
                "                   s=60, c='r', marker='^', edgecolors='k')\n",
                "    else:\n",
                "        ax.scatter(X0, X1, c=y, cmap=plt.cm.coolwarm, s=50, edgecolors='k', linewidth=1)\n",
                "\n",
                "    ax.set_xlim(xx.min(), xx.max())\n",
                "    ax.set_ylim(yy.min(), yy.max())\n",
                "    #     ax.set_xlabel(data.feature_names[0])\n",
                "    #     ax.set_ylabel(data.feature_names[1])\n",
                "    if ticks:\n",
                "        ax.set_xticks(())\n",
                "        ax.set_yticks(())\n",
                "        #     ax.set_title(title)\n",
                "    if show:\n",
                "        plt.show()\n",
                "    else:\n",
                "        return ax\n",
                "    \n",
                "\n",
                "def plot_4_classifiers(X, y, clfs):\n",
                "    # Set-up 2x2 grid for plotting.\n",
                "    fig, sub = plt.subplots(2, 2)\n",
                "    plt.subplots_adjust(wspace=0.2, hspace=0.2)\n",
                "    \n",
                "    for clf, ax, title in zip(clfs, sub.flatten(), (\"(1)\", \"(2)\", \"(3)\", \"(4)\")):\n",
                "        # clf.fit(X, y)\n",
                "        plot_classifier(X, y, clf, ax, ticks=True)\n",
                "        ax.set_title(title)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/tmp/ipykernel_14591/3944463996.py:71: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n",
                        "  ax.scatter(X0[y==labels[0]], X1[y==labels[0]], cmap=plt.cm.coolwarm,\n",
                        "/tmp/ipykernel_14591/3944463996.py:73: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n",
                        "  ax.scatter(X0[y==labels[1]], X1[y==labels[1]], cmap=plt.cm.coolwarm,\n",
                        "/tmp/ipykernel_14591/3944463996.py:71: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n",
                        "  ax.scatter(X0[y==labels[0]], X1[y==labels[0]], cmap=plt.cm.coolwarm,\n",
                        "/tmp/ipykernel_14591/3944463996.py:73: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n",
                        "  ax.scatter(X0[y==labels[1]], X1[y==labels[1]], cmap=plt.cm.coolwarm,\n",
                        "/tmp/ipykernel_14591/3944463996.py:71: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n",
                        "  ax.scatter(X0[y==labels[0]], X1[y==labels[0]], cmap=plt.cm.coolwarm,\n",
                        "/tmp/ipykernel_14591/3944463996.py:73: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n",
                        "  ax.scatter(X0[y==labels[1]], X1[y==labels[1]], cmap=plt.cm.coolwarm,\n",
                        "/tmp/ipykernel_14591/3944463996.py:71: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n",
                        "  ax.scatter(X0[y==labels[0]], X1[y==labels[0]], cmap=plt.cm.coolwarm,\n",
                        "/tmp/ipykernel_14591/3944463996.py:73: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n",
                        "  ax.scatter(X0[y==labels[1]], X1[y==labels[1]], cmap=plt.cm.coolwarm,\n"
                    ]
                },
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 640x480 with 4 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.svm import SVC, LinearSVC\n",
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "\n",
                "# Define the classifiers\n",
                "classifiers = [LogisticRegression(), LinearSVC(),\n",
                "               SVC(), KNeighborsClassifier()]\n",
                "\n",
                "# Fit the classifiers\n",
                "for c in classifiers:\n",
                "    c.fit(X, y)\n",
                "\n",
                "# Plot the classifiers\n",
                "plot_4_classifiers(X, y, classifiers)\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Loss functions\n",
                "\n",
                "### Changing the model coefficients\n",
                "\n",
                "When you call `fit` with scikit-learn, the logistic regression\n",
                "coefficients are automatically learned from your dataset. In this\n",
                "exercise you will explore how the decision boundary is represented by\n",
                "the coefficients. To do so, you will change the coefficients manually\n",
                "(instead of with `fit`), and visualize the resulting classifiers.\n",
                "\n",
                "A 2D dataset is already loaded into the environment as `X` and `y`,\n",
                "along with a linear classifier object `model`.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Set the two coefficients and the intercept to various values and\n",
                "  observe the resulting decision boundaries.\n",
                "- Try to build up a sense of how the coefficients relate to the decision\n",
                "  boundary.\n",
                "- Set the coefficients and intercept such that the model makes no errors\n",
                "  on the given training data.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<style>#sk-container-id-1 {\n",
                            "  /* Definition of color scheme common for light and dark mode */\n",
                            "  --sklearn-color-text: black;\n",
                            "  --sklearn-color-line: gray;\n",
                            "  /* Definition of color scheme for unfitted estimators */\n",
                            "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
                            "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
                            "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
                            "  --sklearn-color-unfitted-level-3: chocolate;\n",
                            "  /* Definition of color scheme for fitted estimators */\n",
                            "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
                            "  --sklearn-color-fitted-level-1: #d4ebff;\n",
                            "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
                            "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
                            "\n",
                            "  /* Specific color for light theme */\n",
                            "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
                            "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
                            "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
                            "  --sklearn-color-icon: #696969;\n",
                            "\n",
                            "  @media (prefers-color-scheme: dark) {\n",
                            "    /* Redefinition of color scheme for dark theme */\n",
                            "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
                            "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
                            "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
                            "    --sklearn-color-icon: #878787;\n",
                            "  }\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 pre {\n",
                            "  padding: 0;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 input.sk-hidden--visually {\n",
                            "  border: 0;\n",
                            "  clip: rect(1px 1px 1px 1px);\n",
                            "  clip: rect(1px, 1px, 1px, 1px);\n",
                            "  height: 1px;\n",
                            "  margin: -1px;\n",
                            "  overflow: hidden;\n",
                            "  padding: 0;\n",
                            "  position: absolute;\n",
                            "  width: 1px;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-dashed-wrapped {\n",
                            "  border: 1px dashed var(--sklearn-color-line);\n",
                            "  margin: 0 0.4em 0.5em 0.4em;\n",
                            "  box-sizing: border-box;\n",
                            "  padding-bottom: 0.4em;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-container {\n",
                            "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
                            "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
                            "     so we also need the `!important` here to be able to override the\n",
                            "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
                            "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
                            "  display: inline-block !important;\n",
                            "  position: relative;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-text-repr-fallback {\n",
                            "  display: none;\n",
                            "}\n",
                            "\n",
                            "div.sk-parallel-item,\n",
                            "div.sk-serial,\n",
                            "div.sk-item {\n",
                            "  /* draw centered vertical line to link estimators */\n",
                            "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
                            "  background-size: 2px 100%;\n",
                            "  background-repeat: no-repeat;\n",
                            "  background-position: center center;\n",
                            "}\n",
                            "\n",
                            "/* Parallel-specific style estimator block */\n",
                            "\n",
                            "#sk-container-id-1 div.sk-parallel-item::after {\n",
                            "  content: \"\";\n",
                            "  width: 100%;\n",
                            "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
                            "  flex-grow: 1;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-parallel {\n",
                            "  display: flex;\n",
                            "  align-items: stretch;\n",
                            "  justify-content: center;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "  position: relative;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-parallel-item {\n",
                            "  display: flex;\n",
                            "  flex-direction: column;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
                            "  align-self: flex-end;\n",
                            "  width: 50%;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
                            "  align-self: flex-start;\n",
                            "  width: 50%;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
                            "  width: 0;\n",
                            "}\n",
                            "\n",
                            "/* Serial-specific style estimator block */\n",
                            "\n",
                            "#sk-container-id-1 div.sk-serial {\n",
                            "  display: flex;\n",
                            "  flex-direction: column;\n",
                            "  align-items: center;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "  padding-right: 1em;\n",
                            "  padding-left: 1em;\n",
                            "}\n",
                            "\n",
                            "\n",
                            "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
                            "clickable and can be expanded/collapsed.\n",
                            "- Pipeline and ColumnTransformer use this feature and define the default style\n",
                            "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
                            "*/\n",
                            "\n",
                            "/* Pipeline and ColumnTransformer style (default) */\n",
                            "\n",
                            "#sk-container-id-1 div.sk-toggleable {\n",
                            "  /* Default theme specific background. It is overwritten whether we have a\n",
                            "  specific estimator or a Pipeline/ColumnTransformer */\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "}\n",
                            "\n",
                            "/* Toggleable label */\n",
                            "#sk-container-id-1 label.sk-toggleable__label {\n",
                            "  cursor: pointer;\n",
                            "  display: block;\n",
                            "  width: 100%;\n",
                            "  margin-bottom: 0;\n",
                            "  padding: 0.5em;\n",
                            "  box-sizing: border-box;\n",
                            "  text-align: center;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
                            "  /* Arrow on the left of the label */\n",
                            "  content: \"▸\";\n",
                            "  float: left;\n",
                            "  margin-right: 0.25em;\n",
                            "  color: var(--sklearn-color-icon);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "}\n",
                            "\n",
                            "/* Toggleable content - dropdown */\n",
                            "\n",
                            "#sk-container-id-1 div.sk-toggleable__content {\n",
                            "  max-height: 0;\n",
                            "  max-width: 0;\n",
                            "  overflow: hidden;\n",
                            "  text-align: left;\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-toggleable__content pre {\n",
                            "  margin: 0.2em;\n",
                            "  border-radius: 0.25em;\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
                            "  /* Expand drop-down */\n",
                            "  max-height: 200px;\n",
                            "  max-width: 100%;\n",
                            "  overflow: auto;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
                            "  content: \"▾\";\n",
                            "}\n",
                            "\n",
                            "/* Pipeline/ColumnTransformer-specific style */\n",
                            "\n",
                            "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                            "  background-color: var(--sklearn-color-fitted-level-2);\n",
                            "}\n",
                            "\n",
                            "/* Estimator-specific style */\n",
                            "\n",
                            "/* Colorize estimator box */\n",
                            "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-2);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
                            "#sk-container-id-1 div.sk-label label {\n",
                            "  /* The background is the default theme color */\n",
                            "  color: var(--sklearn-color-text-on-default-background);\n",
                            "}\n",
                            "\n",
                            "/* On hover, darken the color of the background */\n",
                            "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                            "}\n",
                            "\n",
                            "/* Label box, darken color on hover, fitted */\n",
                            "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  background-color: var(--sklearn-color-fitted-level-2);\n",
                            "}\n",
                            "\n",
                            "/* Estimator label */\n",
                            "\n",
                            "#sk-container-id-1 div.sk-label label {\n",
                            "  font-family: monospace;\n",
                            "  font-weight: bold;\n",
                            "  display: inline-block;\n",
                            "  line-height: 1.2em;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-label-container {\n",
                            "  text-align: center;\n",
                            "}\n",
                            "\n",
                            "/* Estimator-specific */\n",
                            "#sk-container-id-1 div.sk-estimator {\n",
                            "  font-family: monospace;\n",
                            "  border: 1px dotted var(--sklearn-color-border-box);\n",
                            "  border-radius: 0.25em;\n",
                            "  box-sizing: border-box;\n",
                            "  margin-bottom: 0.5em;\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-estimator.fitted {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-0);\n",
                            "}\n",
                            "\n",
                            "/* on hover */\n",
                            "#sk-container-id-1 div.sk-estimator:hover {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-2);\n",
                            "}\n",
                            "\n",
                            "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
                            "\n",
                            "/* Common style for \"i\" and \"?\" */\n",
                            "\n",
                            ".sk-estimator-doc-link,\n",
                            "a:link.sk-estimator-doc-link,\n",
                            "a:visited.sk-estimator-doc-link {\n",
                            "  float: right;\n",
                            "  font-size: smaller;\n",
                            "  line-height: 1em;\n",
                            "  font-family: monospace;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "  border-radius: 1em;\n",
                            "  height: 1em;\n",
                            "  width: 1em;\n",
                            "  text-decoration: none !important;\n",
                            "  margin-left: 1ex;\n",
                            "  /* unfitted */\n",
                            "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
                            "  color: var(--sklearn-color-unfitted-level-1);\n",
                            "}\n",
                            "\n",
                            ".sk-estimator-doc-link.fitted,\n",
                            "a:link.sk-estimator-doc-link.fitted,\n",
                            "a:visited.sk-estimator-doc-link.fitted {\n",
                            "  /* fitted */\n",
                            "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
                            "  color: var(--sklearn-color-fitted-level-1);\n",
                            "}\n",
                            "\n",
                            "/* On hover */\n",
                            "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
                            ".sk-estimator-doc-link:hover,\n",
                            "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
                            ".sk-estimator-doc-link:hover {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-3);\n",
                            "  color: var(--sklearn-color-background);\n",
                            "  text-decoration: none;\n",
                            "}\n",
                            "\n",
                            "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
                            ".sk-estimator-doc-link.fitted:hover,\n",
                            "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
                            ".sk-estimator-doc-link.fitted:hover {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-3);\n",
                            "  color: var(--sklearn-color-background);\n",
                            "  text-decoration: none;\n",
                            "}\n",
                            "\n",
                            "/* Span, style for the box shown on hovering the info icon */\n",
                            ".sk-estimator-doc-link span {\n",
                            "  display: none;\n",
                            "  z-index: 9999;\n",
                            "  position: relative;\n",
                            "  font-weight: normal;\n",
                            "  right: .2ex;\n",
                            "  padding: .5ex;\n",
                            "  margin: .5ex;\n",
                            "  width: min-content;\n",
                            "  min-width: 20ex;\n",
                            "  max-width: 50ex;\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  box-shadow: 2pt 2pt 4pt #999;\n",
                            "  /* unfitted */\n",
                            "  background: var(--sklearn-color-unfitted-level-0);\n",
                            "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
                            "}\n",
                            "\n",
                            ".sk-estimator-doc-link.fitted span {\n",
                            "  /* fitted */\n",
                            "  background: var(--sklearn-color-fitted-level-0);\n",
                            "  border: var(--sklearn-color-fitted-level-3);\n",
                            "}\n",
                            "\n",
                            ".sk-estimator-doc-link:hover span {\n",
                            "  display: block;\n",
                            "}\n",
                            "\n",
                            "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
                            "\n",
                            "#sk-container-id-1 a.estimator_doc_link {\n",
                            "  float: right;\n",
                            "  font-size: 1rem;\n",
                            "  line-height: 1em;\n",
                            "  font-family: monospace;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "  border-radius: 1rem;\n",
                            "  height: 1rem;\n",
                            "  width: 1rem;\n",
                            "  text-decoration: none;\n",
                            "  /* unfitted */\n",
                            "  color: var(--sklearn-color-unfitted-level-1);\n",
                            "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
                            "  /* fitted */\n",
                            "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
                            "  color: var(--sklearn-color-fitted-level-1);\n",
                            "}\n",
                            "\n",
                            "/* On hover */\n",
                            "#sk-container-id-1 a.estimator_doc_link:hover {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-3);\n",
                            "  color: var(--sklearn-color-background);\n",
                            "  text-decoration: none;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-3);\n",
                            "}\n",
                            "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
                        ],
                        "text/plain": [
                            "LogisticRegression()"
                        ]
                    },
                    "execution_count": 36,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# added/edited\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "\n",
                "model = LogisticRegression()\n",
                "model.fit(X, y)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/tmp/ipykernel_14591/3944463996.py:71: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n",
                        "  ax.scatter(X0[y==labels[0]], X1[y==labels[0]], cmap=plt.cm.coolwarm,\n",
                        "/tmp/ipykernel_14591/3944463996.py:73: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n",
                        "  ax.scatter(X0[y==labels[1]], X1[y==labels[1]], cmap=plt.cm.coolwarm,\n"
                    ]
                },
                {
                    "data": {
                        "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAGdCAYAAABO2DpVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAsm0lEQVR4nO3df3TU9Z3v8ddMggiBhB/KJmjir0AsP+9p5bYVQTkKyrYqsBXLZZVuQV0Esbvu1ka7au6WDbb32BqhHEEsclbqwXMSbKkQ8Fz5VasiyIo/rpWIEJDIamEmZJKB8v3eP8KEJMxMZpLPzHe+33k+zplzGvJN5pOJzby+nx/vt8+2bVsAAAAG+J0eAAAA8A6CBQAAMIZgAQAAjCFYAAAAYwgWAADAGIIFAAAwhmABAACMIVgAAABjctP9hJZl6fPPP1f//v3l8/nS/fQAAKAbbNtWY2Ojhg4dKr8/9rxE2oPF559/ruLi4nQ/LQAAMKC+vl6XXnppzM+nPVj0799fkvT0ukPq0zc/3U8PAAC6oTkU1IMzS9rex2NJe7CILH/06ZuvvnkECwAA3KSrbQxs3gQAAMYQLAAAgDEECwAAYAzBAgAAGEOwAAAAxhAsAACAMQQLAABgDMECAAAYQ7AAAADGECwAAIAxBAsAAGAMwQIAABhDsAAAAMYQLAAAgDEECwAAYAzBAgAAGEOwAAAAxhAsAACAMQQLAABgDMECAAAYQ7AAAADGECwAAIAxBAsAAGAMwQIAABhDsAAAAMYQLAAAgDEECwAAYAzBAgAAGEOwAAAAxhAsAACAMQQLAABgDMECAAAYQ7AAAADGECwAAIAxBAsAAGAMwQIAABhDsAAAAMYQLAAAgDEECwAAYAzBAgAAGEOwAAAAxhAsAACAMQQLAABgDMECAAAYQ7AAAADGECwAAIAxBAsAAGAMwQIAABhDsAAAAMYQLAAAgDEECwAAYAzBAgAAGJNUsHjiiSfk8/k6PK6++upUjQ0AALhM0jMWI0eO1NGjR9seO3fuTMW4AABJCLeEtLlmqcItIaeHgiyXm/QX5OaqsLAwFWMBAHRTbXWV1q18ROGWJt0662Gnh4MslvSMxSeffKKhQ4fqyiuv1OzZs3Xo0KG414fDYQWDwQ4PAIA5zaFGbVr7pPpJ2vjiErU0n3R6SMhiSQWLb37zm1q9erU2bdqk5cuX68CBA5owYYIaGxtjfk1lZaUKCgraHsXFxT0eNADgnC3rl6k5FNQmSc2hoLasX+b0kJDFfLZt29394hMnTuiyyy7TU089pblz50a9JhwOKxwOt30cDAZVXFysFRtOqG9efnefGgCg1tmKh2aWaHZTQL+WNF/S2rwCPfVyvS7s08/p4cFDQk1B3fvdAQoEAsrPj/3+3aPjpgMGDNDw4cO1f//+mNf07t1b+fn5HR4AADMisxXlZz8uF7MWcFaPgsXJkydVV1enoqIiU+MBACQosrdinm0rsshcImmubbPXAo5JKlj8y7/8i7Zt26bPPvtMb7zxhqZPn66cnBzNmjUrVeMDAMTQebYiglkLOCmpYHH48GHNmjVLZWVlmjlzpgYPHqw333xTF198carGBwCIItpsRQSzFnBSUnUsXnrppVSNAwCQhFizFRHlkladnbWgrgXSiV4hAOAy8WYrIpi1gFOSrrwJAHDWzto1CjYF9Ko/R6P9se8PGy1LwaaAdtSu0eRp96dxhMhmBAsAcJmyMRM0ZfpC2YpfhqhIUpl8Kht9XXoGBohgAQCuU3LVGN29qMrpYQBRsccCAAAYQ7AAAADGECwAAIAxBAsAAGAMwQIAABhDsAAAAMYQLAAAgDEECwAAYAzBAoBrhFtC2lyzVOGWkNND6RGv/BxANAQLAK5RW12lNVWLtLnmGaeH0iNe+TmAaAgWAFwh0tGzn+Tqjp1e+TmAWAgWAFxhy/plag4FtUlScyioLeuXOT2kbvHKzwHEQrAAkPEid/nzbFvjJc21bVfe7Xvl5wDiIVgAyHiRu/zysx+Xy513+175OYB4CBYAMlr7u/zis/9WIvfd7Xvl5wC6QrAAkNE63+VHuO1u3ys/B9AVggWAjBXtLj/CTXf7Xvk5gEQQLABkrFh3+RFuudv3ys8BJIJgASAjxbvLj3DD3b5Xfg4gUblODwAAotlZu0bBpoBe9edotD/2PVCjZSnYFNCO2jWaPO3+NI4wMV75OYBEESwAZKSyMRM0ZfpC2bLjXlckqUw+lY2+Lj0DS5JXfg4gUT7btuP/125YMBhUQUGBVmw4ob55+el8agAA0E2hpqDu/e4ABQIB5efHfv9mjwUAADCGYAEAAIwhWAAAAGMIFgAAwBiCBQAAMIZgAQAAjCFYAAAAYwgWAADAGIIFAAAwhmABAACMIVgAAABjCBYAAMAYggUAADCGYAEAAIwhWAAAAGMIFgAAwBiCBQAAMIZgAQAAjCFYAAAyQrglpM01SxVuCTk9FPQAwQIAkBFqq6u0pmqRNtc84/RQ0AMECwCA45pDjdq09kn1k7TxxSVqaT7p9JDQTQQLAIDjtqxfpuZQUJskNYeC2rJ+mdNDQjcRLAAAjorMVsyzbY2XNNe2mbVwMYIFAMBRkdmK8rMfl4tZCzcjWAAAHNN+tqL47L+ViFkLN8t1egAAgOzVebYiolzSqrOzFrfOeliSVP/pPu3aUa3QyRPq22+Axk2YoeIrR6d9zIivRzMWS5Yskc/n049+9CNDwwEAZItosxUR7WctDtb9lyoWXq/yuWO1fk2VtqzfovVrqlQ+d6wqHrhBDUf2OzF8xNDtYLFr1y49++yzGjNmjMnxAACyRKzZiojIXosn7r9OdR81SFony/pCZ/76gSzrC0nrVPfhUT0+fzzhIoN0K1icPHlSs2fP1sqVKzVw4EDTYwIAeFy82YqIyKyFdapZlrVZ0h2Sep39bC9Jd8iy3lBz0wCtWDIvHcNGAroVLBYsWKDvfOc7uummm0yPBwCQBXbWrlGwKaBX/Tkandsr6mNUTq42SDojS9KrMb7TRbKsn+nP729X/af70vgTIJakN2++9NJL2rNnj3bt2pXQ9eFwWOFwuO3jYDCY7FMCADymbMwETZm+ULbsmNfUffS2Dv+/9yTNk3RdnO82TX7/QL2zo4bNnBkgqWBRX1+vBx98UFu2bNGFF16Y0NdUVlaqoqKiW4MDgFQKt4S0bePzun7qD9X7wr5ODyerlFw1Rncvqop7zX8u+ycd3N+kM39d2sV3u0A+f6GaTh43N0B0W1JLIbt379axY8f09a9/Xbm5ucrNzdW2bdtUVVWl3NxcnTlz5ryvKS8vVyAQaHvU19cbGzwA9ARNrzJb334DZFtHJZ3u4spTsq0G5fVjz18mSCpY3Hjjjdq3b5/27t3b9rjmmms0e/Zs7d27Vzk5Oed9Te/evZWfn9/hASD7ZFpLbJpeZb5xE2bIso5LWt/FletlWcd1zcQZaRgVupJUsOjfv79GjRrV4ZGXl6fBgwdr1KhRqRojAA/ItNkBml5lvuIrR2vYyAny+x+V9GWMq76U3/9TDR81UcVX8D6UCSjpDSDlMm12gKZX7nFf+Sr1yTshv/9aSesknTr7mVOS1snvv1Z98k7o3p8859wg0UGPg8XWrVv1q1/9ysBQAHhVps0O0PTKPQovKVXF8j+qdESRpDvl9xcqJ3eE/P5CSXeqdESRKpb/UYWXlDo9VJzls2079lmfFAgGgyooKNCKDSfUN4/9FoDXNYca9dDMEs1uCujXkuZLWptXoKderteFffr16Ht3p3dE5/FEmBwXUqP+0316Z0eNmk4eV16/gbpm4gyWP9Io1BTUvd8doEAgEHe/JE3IAKRUtNmBzs2lktVwZL+erZyrTz7YIb9/oHz+ItnWUVWvrtCwURN130+ei3kHm0zTK2SW4itHU6fCBdhjASBlUtESu+HIfj0+f3y3ekck2vSKvRZA9xEsAKRMvNmB7u5peLZyrpqbBsiy3lCyvSMSbXrFXgug+wgWAFIiFbMD9Z/u0ycf7JBlLZZ0UYyroveOSKbpFbMWQPcRLACkRCpmB3btqJbfP1DStC6uPNc7IiKRplejc3tpoz9HwaaAdtSuSXhcAM5h8yYA45KZHVj74hJNnrYgoZMYoZMn5PMXSVavLq48v3dEIk2vJKlIUpl8Khsdr+kVgFgIFgCM6zA74I89MdpoWW2zA5On3d/l9+3YOyJeuDi/d0QiTa8A9BzBAoBxqZodGDdhhqpXV6i1d8Qdca6kdwTgFIIFAONSNTsQ6R1R99GjsqxJir6Bs7V3ROkIekcATmDzJgBXoXcEkNkIFgBchd4RQGZjKQSA6xReUqrHntlK7wggAxEsALgWvSOAzMNSCAAAMIZgAQAAjCFYAEiLcEtIm2uWKtwScnooAFKIYAEgLWqrq7SmapE21zzj9FAApBDBAkDKRXqH9JPoHAp4HMECQMpFOp1uUvIdTQG4C8ECQEq173Q6Xq0dTZm1ALyLYAEgpSKzFeVnPy4XsxaAlxEsAKRM+9mK4rP/ViJmLQAvI1gASJnOsxURzFoA3kWwAJAS0WYrIpi1ALyLYAEgJWLNVkQwawF4E8ECgHHxZisimLUAvInupgCM21m7RsGmgF7152i0P/b9S6NlKdgU0I7aNZo87f40jhBAqhAsABhXNmaCpkxfKFt23OuKJJXJp7LR1533uXBLSNs2Pq/rp/5QvS/sm6KRAjCNYAHAuJKrxujuRVU9+h611VVat/IRhVuadOushw2NDECqsccCQMahtwjgXgQLABmH3iKAexEsAGQUeosA7kawAJBR6C0CuBvBAkDGoLcI4H4ECwAZg94igPsRLABkBK/1Fgm3hLS5ZqnCLSGnhwKkFcECQEbwWm+R2uoqralapM01zzg9FCCtCBYAHOe13iLU4UA2I1gAcFyH3iK5vWI+Nvpz2nqLZDLqcCCbUdIbgONM9BbJFNHqcKx9cYkmT1ugC/v0c3p4QMoRLAAPcWvjLhO9RTJFtDocq87OWnS354lbf6/ITiyFAB7ChkFnpaoOB79XuAnBAvAINgw6LxV1OPi9wm0IFoBHsGHQWamowxFuCenXi/9eoaYAv1e4BsEC8AAadzkvFXU4/vDSL/TuG7/XNRK/V7gGwQLwABp3OSsVdTiaQ43a+NvWJZCPJZ0Uv1e4A8ECcDkadzkvFXU4Nq57SqdPtWiTWkPFMvF7hTtw3BRwuXgbBnt6zBGJMV2HIzJbcY/OLoFI+oWkBeL3iszns207/v8TDAsGgyooKNCKDSfUNy8/nU8NeE5zqFEPzSzR7KaAfh3l8/Mlrc0r0FMv13dZnIlaCZmjenWFfvdChT6VVCzpkKRSSf8u6WEl93sFTAk1BXXvdwcoEAgoPz/2+zdLIYCLmdwwSK2EzNB+tqLD0pZaZy3Ya4FMR7AAXMrkhkFqJWSOyN6KaEtbQbHXApmPYAG4lMkNg9TAyAytsxU/7zBbERGZtXhM0oicXNc0ZEP2SWrz5vLly7V8+XJ99tlnkqSRI0fqscce09SpU1MxNgBxmNowSNOszLFl/TL99fT5sxUR5ZKek3T66nEaPvzrGd+QDdkpqWBx6aWXasmSJRo2bJhs29YLL7yg22+/Xe+++65GjhyZqjECiMJU465UNM0yKVs2lSa6tDVP0trPPtRPflFL8ENGSmop5NZbb9Xf/u3fatiwYRo+fLgWL16sfv366c0330zV+ACkkBtqYGTLptJU1MIAnNDtOhZnzpzRyy+/rKamJn3729+OeV04HFY4HG77OBgMdvcpARiW6TUwOm8q9fLyjOlaGIBTkg4W+/bt07e//W21tLSoX79+qqmp0YgRI2JeX1lZqYqKih4NEoB5iTTNcnqvRST4vC5pUgYEnVQytbQFOC3pUyFlZWXau3ev3nrrLc2fP19z5szRhx9+GPP68vJyBQKBtkd9fX2PBgykW7glpM01SxVuCTk9FKNS0TTLJBqrAe6UdLC44IILVFpaqm984xuqrKzU2LFj9fTTT8e8vnfv3srPz+/wANzEi2v8qWiaZRqN1QB36nEdC8uyOuyhALzEq4WjMn2joBs2lQKILqk9FuXl5Zo6dapKSkrU2NiotWvXauvWraqtrU3V+ABHeXWNP9M3Cmb6plIAsSUVLI4dO6a7775bR48eVUFBgcaMGaPa2lpNnjw5VeMDHOPlwlGZvFHQDZtKAcSW1FLIqlWr9NlnnykcDuvYsWN67bXXCBXwLNb4nZHsplKvbq4F3IpeIUAUrPE7ozubSr24uRZwM4IFEEW8NX5mLVIn2U2l//f3Kzy5uRZws25X3gS8ijV+5yS7qfSrLw55cnMt4GYEC6CTRNb4OZmQGslsKm0ONeqhmSWe3FwLuBlLIUA7bigchVZsrgUyE8ECaCfTC0ehFZtrgczFUgjQTqYXjkIrCmgBmYtgAbSTyYWj0IrNtUBmYykEgKtkeldWINsRLAC4BptrgczHUggA1+iwudYf+76o0bLaNtdOnnZ/GkcIgGABwDXYXAtkPoIFANdgcy2Q+dhjAQAAjCFYAAAAYwgWAADAGIIFkMXCLSFtrlmqcEvI6aEA8AiCBZDFaqurtKZqkTbXPOP0UAB4BMECyFKRYlP9JIpJATCGYAFkqUhp7E2iBDYyD8t07kWwALJQ+9LY40UJbGQelunci2ABZKHOjbxo3IVMwjKduxEsgCwTrZEXjbuQSVimczeCBZBlYrUdZ9YCmYBlOvcjWABZJF7bcWYtkAlYpnM/ggWQRWLNVkTwRxxOYpnOGwgWyCgcMUudeLMVEfwRh5NYpvMGggUyCkfMUmdn7RoFmwJ61Z+j0bm9Yj42+nMUbApoR+0ap4eMLMIynXfkOj0AIKLzEbPJ0xbowj79nB6WZ5SNmaAp0xfKlh33uiJJZfKpbPR16RkYoMSW6VadnbW4ddbD6RwakkSwQMaI/GF5XdIk/oAYV3LVGN29qMrpYQDnSWaZbi03HRmPpRBkBI6YAdmLZTpvYcYCGSHaETOmPbNXuCWkbRuf1/VTf6jeF/Z1ejhIMZbpvIVgAcfFO2LGtGd2qq2u0rqVjyjc0kSwzAIs03kLSyFwHEfM0B59IgB3I1jAURwxQ2f0iQDcjWABR1EJEu2xiRdwP4IFHEMlSHRGnwjA/QgWcAxHzNAefSIAb+BUCBzDETO0F28TL0ePAfcgWMAxHDFDRCKbeDl6DLgDSyEAHMcmXsA7CBYAHMUmXsBbWAoB4KgOm3j9se91Gi2rbRPv5Gn3p3GEAJJBsADaoUdF+rGJF/AWggXQDj0q0o9NvIC3sMcCOIseFQDQcwQL4Cx6VABAzxEs4EnhlpA21yxVuCWU0PX0qAAAM9hjAU9Kdq9EtB4VVHv0nvpP92nXjmqFTp5Q334DNG7CDBVfOdrpYQGe4rNtO/5WbMOCwaAKCgq0YsMJ9c3LT+dTI0s0hxr10MwSWU0B+fMK9NTL9XGrNUaun90U0K/b/ft8SWsT+HpkvoYj+/Vs5Vx98sEO+f0D5fMXybaOyrKOa9ioibrvJ8+p8JJSp4cJZLRQU1D3fneAAoGA8vNjv3+zFALPSXavRLweFey1cL+GI/v1+PzxqvuoQdI6WdYXOvPXD2RZX0hap7oPj+rx+ePVcGS/00MFPIFgAU9Jdq9EIj0q2Gvhbs9WzlVz0wBZ1huS7pDU6+xnekm6Q5b1hpqbBmjFknnODRLwEIIFPCXaXol4sw70qPC2+k/36ZMPdsiyFku6KMZVF8myfqY/v79d9Z/uS+fwAE9KKlhUVlZq3Lhx6t+/v4YMGaJp06bp448/TtXYgKREm32IN+tAjwrv27WjWn7/QEnTurhymvz+gXpnR00aRgV4W1LBYtu2bVqwYIHefPNNbdmyRadPn9aUKVPU1NSUqvEBCUt2r0SHHhW5vWI+Nvpz2npUwF1CJ0/I5y/SueWPWC6Qz1+oppPH0zEswNOSOm66adOmDh+vXr1aQ4YM0e7duzVx4kSjAwOSkcheibUvLtHkaQvaTnjQo8L7+vYbINs6Kum04oeLU7KtBuX1G5imkQHe1aM6FoFAQJI0aNCgmNeEw2GFw+G2j4PBYE+eEogqkb0SnetS0KPC+8ZNmKHq1RWS1qt142Ys62VZx3XNxBnpGRjgYd0OFpZl6Uc/+pHGjx+vUaNGxbyusrJSFRUV3X0aoEvJ7JXoPGsBbyu+crSGjZyguo8elWVNUvQNnF/K7/+pSkdMVPEVsf+WeVUiRcMoLIZkdLtA1vz587Vx40bt3LlTl156aczros1YFBcXUyALxmypWaYXqh7QZf4c9ffH3jbUaFk6aJ3RnAeXavK0+9M4QjgpUsei9cjpz9S6kfMCSackrZff/1P1yTuhiuV/zKoiWYkUDZPU4RpbQyS7QbYd0GWl39ADT/w2q16zbJdogaxuBYuFCxfqlVde0fbt23XFFVck9bVU3oRph+re09Y/PNflXglJ8smnG74zTyVXjUnDyJApGo7s14ol8/Tn97effRMtlG01yLKOa/ioibo3yypvdgxbi9UatnqpdS/Kevn9j6p3n68k+RRuHhT1Gulh+XOO6sdP/l6jvnGjIz8H0islwcK2bT3wwAOqqanR1q1bNWzYsKQHRrAA4JT6T/fpnR01ajp5XHn9BuqaiTOycvmjYuH1qvuo4WzRsOjLQ9Llkv5G0ltxrvmm/P4j+vmafVkVzLJVosEiqT0WCxYs0Nq1a/XKK6+of//+amhokCQVFBSoT58+PRsxAKRY8ZWjs35vQKRomLROsYuGHZXUJGlJnGsuklQpy7pTzzwxS4tX7jI/WLhSUsFi+fLlkqQbbrihw7//5je/0Q9+8ANTYwIAGBBt02WkaJhlTYvzldWSEissJg3Qwf27Vf/pvqwPbWiVVLBIcyNUAB4Ubglp28bndf3UH6r3hX2dHo4nxdqYWb26QgMGXyr5Bit+XY8Taq3g0nVhsdbrmvXOjhqCBST1sI4FACSrtrpK61Y+onBLU1tNEUTXnWOe7TdmtnZznSZZ5zZdBv5SLtv+TNJHkr4W47sMUOtySNeFxaQG+fz9qVqKNgQLAGkTqTnST9JGaorEFG/GIXIUNNZmyY7dXNvvj2jt5mrbkyT9T0nfk/RBjBHMkPSEEiksJh2X7HyqlqIN3U0BpE2kQuom0TU2lsiMQ91HDWqdcfhCZ/76gSzrC0nrVPfhUT0+f7wajuw/72sT7ebauinzQ0nbY1xTJClP0sNqPf0RzZeSfipphGw7SNVStCFYAEiL9hVSx4uusbF0nHG4Q+eWIlpnHCzrDTU3DdCKJfPO+9pkurlK+fL5pqv1dMips/9+StI6+f3Xqk9eb/n9n0v6ZtRrpGslHZfP16Tho7KzaimiI1gASIvO/VxidZ3NZonOOFjWz/Tn97er/tN9HT6TTDfXnJyhKhjUR9Kd8vsLlZM7Qn5/oaQ7VTqiSP/+7Jv68c83yO8/IulOtda0GCGp8OzHveTz5alvv5DuPVulE5DYYwHExOkFc6L1c6F/y/kSOwoqSdPk9w887yRGUt1c7S90460P6poJ02MWDSu8pFQ/X7NPzzwxSwf375bULJ+/v2Tny7Y/1LCR2Ve1FF0jWAAxcHrBnFjdZ6N1nc1mbTMOVtczDj5/4XknMbrTzbX4ilFxT5oUXlKqxSt3UbUUCSNYAFFwesGceN1nmbXoKKkZB6vhvJMYqezmStVSJIo9FvCscEtIm2uWKtwSSvprOb1gTqzZigj2WpwzbsIMWdZxtc44xHNuxqGz+8pXqU/eCfn91yr2xswT3d4XUf/pPlW/UKH/XPZPqn6h4rx9Hj29Hu7X7bbp3UUTMqTL79Yu0bqVj+jOeyuTmmZvDjXqoZklmt0U0K8lzZe0Nq9AT71cn/V31Mnq/FrGwmt8zrkGYa9J+p2kH0pqv8fnS/n916r4ynx947rvRi2elYpurom0WW//PZO9HpkvpW3Te4JggXSIvKFZTQH5k3zD+t3aJap57lHVnZ26PySp1OfTjHv+g30ASdpSs0wvVD2gy/w56u+PPUHaaFk6aJ3RnAeXavK0+9M4QjO6UyEzlkgdi9BJS7b9laTFkh5R64zDevl8P5bP1yDLCnf5hm1qX0Qibdb75J1QxfI/qvCS0qSvhzsQLJDVIuHgddvWpCRCQaw7bK/cUaf7pMuhuve09Q/PyVbXf2Z88umG78xTyVVjUj4uU1J1V/7Z/r363/eN0wXWGTXLJztnuGQfk2Udlz/nQskuTusbdiJt1v3+a1U6okiPPbM16evhDilpmw64QbRCTIluDnT76YWugkPnky6pDholV43R3YuqjH/fTNBVT466Dx/V4/PHd+tN/r23N8m2LW2SdINsXfW1izT6mlnateP3OnwgGLNct2VNUnPTtVqxZJ6xN+zE2qxHamvcqV3bq5O6nq6o3sPmTXhOdwsxJXJ6IdMrRdZWV2lN1SJtrnnmvM91PunS0nwy7vWIrycVMuPpHIznSWo48L5Gj7tZh+p2d7t4VnclU83T7x+ozTVLk7r+nR01JoaJDEKwgKfEK8TUVShw++mFaMGhvc4nXV5d91Tc6xFbTytkxhMrGL/8/E8decNOppqnz1+Y9PV0RfUeggU8Jd5SRrxQEG+2IiLTZy3iHZGNtjz0hxcrOVLbTcnexSf6Jh8vGNe9t0Py/Y3S8Ybd/ojowf1729XWiKe1tkbHWhxdX09XVO8hWMAzerKUsbN2jYJNAb3qz9Ho3F4xHxv9OQo2BbSjdk1afqZEddXgq3PgekDSmdNhGoJ1U6ruyuMF47+ePiXbOqhUvmE3HNmvioXXq3zuWK1fU6Ut67fo//3Xu0nV1pgyfWGPa3HA3di8Cc9IZCkj1gbMsjETNGX6wi5PLxRJKpNPZaOvMzJmU6JNn0d+1ptuv/+8wPW7dtd1vj6TN6dmip5WyIymq2A8T9JKu1ln9JKku+J8p+69YcffjPo/JP1EUtfVPMdNnJGy6p9wB4JFFvFyU61kljKinRBx8+mFrhp8nTrV0iF0NEr6P5LukWgI1k3d6cnRlUSC8XOSfL5/km1Plek37I6bUTufOHlF0rfV2kK9Uq1LQBcoUlvD7//p2Wqef5DUWv2zNaRcK8v6WZfXw1tYCskiXj4B4PaljJ7oal/Jqy92DB3LJAWlpPeheElPy0xHenL4/Y9K+jLGVa1v8sNHdf0mn2gwnicpx/6LfL5vyWS57q43o5ZK+pOkCxWrzXr7Y7WFl5SqYvkfVTqiKKHr4S0UyMoSPalE6QZeL8QUS1cls+er9S53n6Sr1TpbcYWkmVLM671QCCwWkwWtOlaXjH1XnsgbaLIVSocUlerY0f3GynVXv1Ch9WuqZFlfqKulHZ/vYn1t7NdVUjo2oWqedEX1DgpkoYPIXe3rkiZ5cC3dzUsZPZHo9Pkrag0WsWYr2l/v1b0WpgtaRe7KW3ty3Hnem3zpiIm69yd/SOh7JbvH54bvzJPP5zP2hp1Mu3Z/ziUqKR2rv1/wy4S+N11Rsw/BIgv0pBIlMlcy0+ePSXren6PPrDOaJ3VrH4rbxd9D0L2qlYWXlOqxZ7b2+K68u8HY1Bt2KjajInsRLLJAvBMDXrsrzSYd9pVEmT63bVu2ZalRtk7ZtgJFV+jUkf3a4PNpm3znXe/z++Xz+dRoWW37UNzYECyaZMtSJ1tm2i135bGapaViMyqyF8HC47o6MeC1u9Jskuj0uSR9TT6VjZmoj9/b7tojtT0RKWhlWdO6uPJcQSs3BIVExdpbUr26om1vCUdEYQrBwuPc3lQLsXVn+vybN3wvRaPJbMnsIfBamelE95Y88PhaPVPxvzgiih7juKmHeaGplteFW0LaXLNU4ZaQ00PxtGwuM51os7Tq1f/OEVEYwYyFh/WkEiXSo3Mbc6RGtu4hSHZvyelws5HNqMhuBAuP6mklSqRe526k/A5SJ1LQKtv2EHR3b4lbNqMiM7EU4lHZXInSLeJ1I4V595WvUp+8E/L7r5XJqpWZzESztJ5WKUX2YcbCo9zeVMvrqC2SfiYLWrlFT+pTJHKSxEuvFcyhpDfggN+tXaKa5x5V3dmlqkOSSn0+zbjnP9hrkQbZsoeg/tN9Kp87Vq0zNPH2lqyTdKcqn39PxVeM6lSufLFaT4icO0ni9z+acLlyeEeiJb0JFkCaxerv4cY+HV7umOsVFQuvV91HDVEqjkZ8Kb//WpWOKGqrONqdr4H3JRos2GMBpFlX3UjdtNfCyx1zvSLZvSVddzqVzp0k2c6eC5yHYAGkkZdqi3Q+1eKGMWejZFuYR06StC5/xHPuJAnQHps3gTTyUm0Rr3fM9ZJkmqVlc5VSmEGwANLES7VFONXiTonUp6DTKXqKpRAgTbxUWyRax1y37Q9BdOMmzJBlHVdrldJ4vFWlFOYwYwGkiVdqi9Ax19uytUopzCFYAGnSnW6kmYiOud53X/mqs3Us6HSK5LEUAmSRnnZT9dKpFsSW7EkSoD1mLIAs0tNuql461YL4kjlJArRH5U0gS0QqflpNAfm7UeEzVsXQztxYQRRA16i8CbhAT5cmktHTbqpeOtUCIHVYCgEc1NOliUSZqDvhlVMtAFKLYAE4pHNJ7FQe04xWdyLZvRBeOdUCILVYCgEc0tOliUTFqzvBCQ4AphEsAAdEW5pI1Zu8l7qpAsh8BAvAAekqiU3dCQDpRrAA0iydSxOJ1J1g1gKASQQLIM3StTSRTDdVZi0AmEKwANIonUsT1J0A4ASOmwJplM6S2NSdAOCEpIPF9u3b9Ytf/EK7d+/W0aNHVVNTo2nTpqVgaIC3JLM0YaL9OHUnADgh6aWQpqYmjR07VsuWsdkLSAZLEwCyQdIzFlOnTtXUqVNTMRbA01iaAJANUr7HIhwOKxwOt30cDAZT/ZRARmJpAkA2SPmpkMrKShUUFLQ9iotjrS4DAAC3S3mwKC8vVyAQaHvU19en+ikBAIBDUr4U0rt3b/Xu3TvVTwMAADIABbIAAIAxSc9YnDx5Uvv372/7+MCBA9q7d68GDRqkkpISo4MDAADuknSweOeddzRp0qS2j//5n/9ZkjRnzhytXr3a2MAAAID7JB0sbrjhBtl2/HP4AAAgO7HHAgAAGEOwAAAAxhAsAACAMQQLAABgDMECAAAYQ7AAAADGECwAAIAxBAsAAGAMwQIAABhDsAAAAMYQLAAAgDEECwAAYAzBAgAAGEOwAAAAxhAsAACAMQQLAABgDMECAAAYQ7AAAADGECwAAIAxBAsAAGAMwQIAABhDsAAAAMYQLAAAgDEECwAAYAzBAgAAGEOwAAAAxhAsAACAMQQLAABgDMECAAAYQ7AAAADGECwAAIAxBAsAAGAMwQIAABhDsAAAAMYQLAAAgDEECwAAYAzBAgAAGEOwAAAAxhAsAACAMQQLAABgDMECAAAYQ7AAAADGECwAAIAxBAsAAGAMwQIAABhDsAAAAMYQLAAAgDG56X5C27YlSc2hYLqfGgAAdFPkfTvyPh6Lz+7qCsMOHz6s4uLidD4lAAAwpL6+XpdeemnMz6c9WFiWpc8//1z9+/eXz+dL51NnpWAwqOLiYtXX1ys/P9/p4WQdXn9n8fo7i9ffOal47W3bVmNjo4YOHSq/P/ZOirQvhfj9/rhJB6mRn5/P/7EdxOvvLF5/Z/H6O8f0a19QUNDlNWzeBAAAxhAsAACAMQQLj+vdu7cef/xx9e7d2+mhZCVef2fx+juL1985Tr72ad+8CQAAvIsZCwAAYAzBAgAAGEOwAAAAxhAsAACAMQQLj9i+fbtuvfVWDR06VD6fT+vXr+/w+erqak2ZMkWDBw+Wz+fT3r17HRmnV8V7/U+fPq2HH35Yo0ePVl5enoYOHaq7775bn3/+uXMD9piu/vt/4okndPXVVysvL08DBw7UTTfdpLfeesuZwXpMV699e//4j/8on8+nX/3qV2kbn9d19fr/4Ac/kM/n6/C45ZZbUjomgoVHNDU1aezYsVq2bFnMz1933XV68skn0zyy7BDv9Q+FQtqzZ4/+7d/+TXv27FF1dbU+/vhj3XbbbQ6M1Ju6+u9/+PDhWrp0qfbt26edO3fq8ssv15QpU/Tf//3faR6p93T12kfU1NTozTff1NChQ9M0suyQyOt/yy236OjRo22P3/72t6kdlA3PkWTX1NRE/dyBAwdsSfa7776b1jFlk3ivf8Tbb79tS7IPHjyYnkFlkURe/0AgYEuyX3vttfQMKkvEeu0PHz5sX3LJJfb7779vX3bZZfYvf/nLtI8tG0R7/efMmWPffvvtaR0HMxaAAwKBgHw+nwYMGOD0ULLOqVOntGLFChUUFGjs2LFOD8fzLMvSXXfdpX/913/VyJEjnR5OVtq6dauGDBmisrIyzZ8/X1999VVKny/tTciAbNfS0qKHH35Ys2bNojFTGm3YsEHf//73FQqFVFRUpC1btuiiiy5yelie9+STTyo3N1eLFi1yeihZ6ZZbbtGMGTN0xRVXqK6uTo888oimTp2qP/3pT8rJyUnJcxIsgDQ6ffq0Zs6cKdu2tXz5cqeHk1UmTZqkvXv36ssvv9TKlSs1c+ZMvfXWWxoyZIjTQ/Os3bt36+mnn9aePXvk8/mcHk5W+v73v9/2v0ePHq0xY8boqquu0tatW3XjjTem5DlZCgHSJBIqDh48qC1btjBbkWZ5eXkqLS3Vt771La1atUq5ublatWqV08PytB07dujYsWMqKSlRbm6ucnNzdfDgQT300EO6/PLLnR5eVrryyit10UUXaf/+/Sl7DmYsgDSIhIpPPvlEr7/+ugYPHuz0kLKeZVkKh8NOD8PT7rrrLt10000d/u3mm2/WXXfdpX/4h39waFTZ7fDhw/rqq69UVFSUsucgWHjEyZMnOyTQAwcOaO/evRo0aJBKSkr0l7/8RYcOHWqrnfDxxx9LkgoLC1VYWOjImL0k3utfVFSk733ve9qzZ482bNigM2fOqKGhQZI0aNAgXXDBBU4N2zPivf6DBw/W4sWLddttt6moqEhffvmlli1bpiNHjuiOO+5wcNTe0NXfns4hulevXiosLFRZWVm6h+pJ8V7/QYMGqaKiQn/3d3+nwsJC1dXV6cc//rFKS0t18803p25QaT2DgpR5/fXXbUnnPebMmWPbtm3/5je/ifr5xx9/3NFxe0W81z9yxDfa4/XXX3d66J4Q7/Vvbm62p0+fbg8dOtS+4IIL7KKiIvu2226z3377baeH7Qld/e3pjOOmZsV7/UOhkD1lyhT74osvtnv16mVfdtll9j333GM3NDSkdEy0TQcAAMaweRMAABhDsAAAAMYQLAAAgDEECwAAYAzBAgAAGEOwAAAAxhAsAACAMQQLAABgDMECAAAYQ7AAAADGECwAAIAxBAsAAGDM/wcA6CWEFd3/WQAAAABJRU5ErkJggg==",
                        "text/plain": [
                            "<Figure size 640x480 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Number of errors: 34\n"
                    ]
                }
            ],
            "source": [
                "# Set the coefficients\n",
                "model.coef_ = np.array([[-1,1]])\n",
                "model.intercept_ = np.array([-3])\n",
                "\n",
                "# Plot the data and decision boundary\n",
                "plot_classifier(X,y,model)\n",
                "\n",
                "# Print the number of errors\n",
                "num_err = np.sum(y != model.predict(X))\n",
                "print(\"Number of errors:\", num_err)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Minimizing a loss function\n",
                "\n",
                "In this exercise you'll implement linear regression \"from scratch\" using\n",
                "`scipy.optimize.minimize`.\n",
                "\n",
                "We'll train a model on the Boston housing price data set, which is\n",
                "already loaded into the variables `X` and `y`. For simplicity, we won't\n",
                "include an intercept in our regression model.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Fill in the loss function for least squares linear regression.\n",
                "- Print out the coefficients from fitting sklearn's `LinearRegression`.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# The squared error, summed over training examples\n",
                "def my_loss(w):\n",
                "    s = 0\n",
                "    for i in range(y.size):\n",
                "        # Get the true and predicted target values for example 'i'\n",
                "        y_i_true = y[i]\n",
                "        y_i_pred = w@X[i]\n",
                "        s = s + (y_i_true - y_i_pred)**2\n",
                "    return s\n",
                "\n",
                "# Returns the w that makes my_loss(w) smallest\n",
                "w_fit = minimize(my_loss, X[0]).x\n",
                "print(w_fit)\n",
                "\n",
                "# Compare with scikit-learn's LinearRegression coefficients\n",
                "lr = LinearRegression(fit_intercept=False).fit(X,y)\n",
                "print(lr.coef_)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Comparing the logistic and hinge losses\n",
                "\n",
                "In this exercise you'll create a plot of the logistic and hinge losses\n",
                "using their mathematical expressions, which are provided to you.\n",
                "\n",
                "The loss function diagram from the video is shown on the right.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Evaluate the `log_loss()` and `hinge_loss()` functions **at the grid\n",
                "  points** so that they are plotted.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Mathematical functions for logistic and hinge losses\n",
                "def log_loss(raw_model_output):\n",
                "   return np.log(1+np.exp(-raw_model_output))\n",
                "def hinge_loss(raw_model_output):\n",
                "   return np.maximum(0,1-raw_model_output)\n",
                "\n",
                "# Create a grid of values and plot\n",
                "grid = np.linspace(-2,2,1000)\n",
                "plt.plot(grid, log_loss(grid), label='logistic')\n",
                "plt.plot(grid, hinge_loss(grid), label='hinge')\n",
                "plt.legend()\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Implementing logistic regression\n",
                "\n",
                "This is very similar to the earlier exercise where you implemented\n",
                "linear regression \"from scratch\" using `scipy.optimize.minimize`.\n",
                "However, this time we'll minimize the logistic loss and compare with\n",
                "scikit-learn's `LogisticRegression` (we've set `C` to a large value to\n",
                "disable regularization; more on this in Chapter 3!).\n",
                "\n",
                "The `log_loss()` function from the previous exercise is already defined\n",
                "in your environment, and the `sklearn` breast cancer prediction dataset\n",
                "(first 10 features, standardized) is loaded into the variables `X` and\n",
                "`y`.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Input the number of training examples into `range()`.\n",
                "- Fill in the loss function for logistic regression.\n",
                "- Compare the coefficients to sklearn's `LogisticRegression`.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# The logistic loss, summed over training examples\n",
                "def my_loss(w):\n",
                "    s = 0\n",
                "    for i in range(y.size):\n",
                "        raw_model_output = w@X[i]\n",
                "        s = s + log_loss(raw_model_output * y[i])\n",
                "    return s\n",
                "\n",
                "# Returns the w that makes my_loss(w) smallest\n",
                "w_fit = minimize(my_loss, X[0]).x\n",
                "print(w_fit)\n",
                "\n",
                "# Compare with scikit-learn's LogisticRegression\n",
                "lr = LogisticRegression(fit_intercept=False, C=1000000).fit(X,y)\n",
                "print(lr.coef_)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Logistic regression\n",
                "\n",
                "### Regularized logistic regression\n",
                "\n",
                "In Chapter 1, you used logistic regression on the handwritten digits\n",
                "data set. Here, we'll explore the effect of L2 regularization.\n",
                "\n",
                "The handwritten digits dataset is already loaded, split, and stored in\n",
                "the variables `X_train`, `y_train`, `X_valid`, and `y_valid`. The\n",
                "variables `train_errs` and `valid_errs` are already initialized as empty\n",
                "lists.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Loop over the different values of `C_value`, creating and fitting a\n",
                "  `LogisticRegression` model each time.\n",
                "- Save the error on the training set and the validation set for each\n",
                "  model.\n",
                "- Create a plot of the training and testing error as a function of the\n",
                "  regularization parameter, `C`.\n",
                "- Looking at the plot, what's the best value of `C`?\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train and validaton errors initialized as empty list\n",
                "train_errs = list()\n",
                "valid_errs = list()\n",
                "\n",
                "# Loop over values of C_value\n",
                "for C_value in [0.001, 0.01, 0.1, 1, 10, 100, 1000]:\n",
                "    # Create LogisticRegression object and fit\n",
                "    lr = LogisticRegression(C=C_value)\n",
                "    lr.fit(X_train, y_train)\n",
                "    \n",
                "    # Evaluate error rates and append to lists\n",
                "    train_errs.append( 1.0 - lr.score(X_train, y_train) )\n",
                "    valid_errs.append( 1.0 - lr.score(X_valid, y_valid) )\n",
                "    \n",
                "# Plot results\n",
                "plt.semilogx(C_values, train_errs, C_values, valid_errs)\n",
                "plt.legend((\"train\", \"validation\"))\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Logistic regression and feature selection\n",
                "\n",
                "In this exercise we'll perform feature selection on the movie review\n",
                "sentiment data set using L1 regularization. The features and targets are\n",
                "already loaded for you in `X_train` and `y_train`.\n",
                "\n",
                "We'll search for the best value of `C` using scikit-learn's\n",
                "`GridSearchCV()`, which was covered in the prerequisite course.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Instantiate a logistic regression object that uses L1 regularization.\n",
                "- Find the value of `C` that minimizes cross-validation error.\n",
                "- Print out the number of selected features for this value of `C`.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Specify L1 regularization\n",
                "lr = LogisticRegression(solver='liblinear', penalty='l1')\n",
                "\n",
                "# Instantiate the GridSearchCV object and run the search\n",
                "searcher = GridSearchCV(lr, {'C':[0.001, 0.01, 0.1, 1, 10]})\n",
                "searcher.fit(X_train, y_train)\n",
                "\n",
                "# Report the best parameters\n",
                "print(\"Best CV params\", searcher.best_params_)\n",
                "\n",
                "# Find the number of nonzero coefficients (selected features)\n",
                "best_lr = searcher.best_estimator_\n",
                "coefs = best_lr.coef_\n",
                "print(\"Total number of features:\", coefs.size)\n",
                "print(\"Number of selected features:\", np.count_nonzero(coefs))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Identifying the most positive and negative words\n",
                "\n",
                "In this exercise we'll try to interpret the coefficients of a logistic\n",
                "regression fit on the movie review sentiment dataset. The model object\n",
                "is already instantiated and fit for you in the variable `lr`.\n",
                "\n",
                "In addition, the words corresponding to the different features are\n",
                "loaded into the variable `vocab`. For example, since `vocab[100]` is\n",
                "\"think\", that means feature 100 corresponds to the number of times the\n",
                "word \"think\" appeared in that movie review.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Find the words corresponding to the 5 largest coefficients.\n",
                "- Find the words corresponding to the 5 smallest coefficients.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get the indices of the sorted cofficients\n",
                "inds_ascending = np.argsort(lr.coef_.flatten()) \n",
                "inds_descending = inds_ascending[::-1]\n",
                "\n",
                "# Print the most positive words\n",
                "print(\"Most positive words: \", end=\"\")\n",
                "for i in range(5):\n",
                "    print(vocab[inds_descending[i]], end=\", \")\n",
                "print(\"\\n\")\n",
                "\n",
                "# Print most negative words\n",
                "print(\"Most negative words: \", end=\"\")\n",
                "for i in range(5):\n",
                "    print(vocab[inds_ascending[i]], end=\", \")\n",
                "print(\"\\n\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Regularization and probabilities\n",
                "\n",
                "In this exercise, you will observe the effects of changing the\n",
                "regularization strength on the predicted probabilities.\n",
                "\n",
                "A 2D binary classification dataset is already loaded into the\n",
                "environment as `X` and `y`.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Compute the maximum predicted probability.\n",
                "- Run the provided code and take a look at the plot.\n",
                "\n",
                "<!-- -->\n",
                "\n",
                "- Create a model with `C=0.1` and examine how the plot and probabilities\n",
                "  change.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Set the regularization strength\n",
                "model = LogisticRegression(C=1)\n",
                "\n",
                "# Fit and plot\n",
                "model.fit(X,y)\n",
                "plot_classifier(X,y,model,proba=True)\n",
                "\n",
                "# Predict probabilities on training points\n",
                "prob = model.predict_proba(X)\n",
                "print(\"Maximum predicted probability\", np.max(prob))\n",
                "\n",
                "# Set the regularization strength\n",
                "model = LogisticRegression(C=0.1)\n",
                "\n",
                "# Fit and plot\n",
                "model.fit(X,y)\n",
                "plot_classifier(X,y,model,proba=True)\n",
                "\n",
                "# Predict probabilities on training points\n",
                "prob = model.predict_proba(X)\n",
                "print(\"Maximum predicted probability\", np.max(prob))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Visualizing easy and difficult examples\n",
                "\n",
                "In this exercise, you'll visualize the examples that the logistic\n",
                "regression model is most and least confident about by looking at the\n",
                "largest and smallest predicted probabilities.\n",
                "\n",
                "The handwritten digits dataset is already loaded into the variables `X`\n",
                "and `y`. The `show_digit` function takes in an integer index and plots\n",
                "the corresponding image, with some extra information displayed above the\n",
                "image.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Fill in the first blank with the *index* of the digit that the model\n",
                "  is most confident about.\n",
                "- Fill in the second blank with the *index* of the digit that the model\n",
                "  is least confident about.\n",
                "- Observe the images: do you agree that the first one is less ambiguous\n",
                "  than the second?\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "lr = LogisticRegression()\n",
                "lr.fit(X,y)\n",
                "\n",
                "# Get predicted probabilities\n",
                "proba = lr.predict_proba(X)\n",
                "\n",
                "# Sort the example indices by their maximum probability\n",
                "proba_inds = np.argsort(np.max(proba,axis=1))\n",
                "\n",
                "# Show the most confident (least ambiguous) digit\n",
                "show_digit(proba_inds[-1], lr)\n",
                "\n",
                "# Show the least confident (most ambiguous) digit\n",
                "show_digit(proba_inds[0], lr)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Fitting multi-class logistic regression\n",
                "\n",
                "In this exercise, you'll fit the two types of multi-class logistic\n",
                "regression, one-vs-rest and softmax/multinomial, on the handwritten\n",
                "digits data set and compare the results. The handwritten digits dataset\n",
                "is already loaded and split into `X_train`, `y_train`, `X_test`, and\n",
                "`y_test`.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Fit a one-vs-rest logistic regression classifier by setting the\n",
                "  `multi_class` parameter and report the results.\n",
                "- Fit a multinomial logistic regression classifier by setting the\n",
                "  `multi_class` parameter and report the results.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fit one-vs-rest logistic regression classifier\n",
                "lr_ovr = LogisticRegression(multi_class=\"ovr\")\n",
                "lr_ovr.fit(X_train, y_train)\n",
                "\n",
                "print(\"OVR training accuracy:\", lr_ovr.score(X_train, y_train))\n",
                "print(\"OVR test accuracy    :\", lr_ovr.score(X_test, y_test))\n",
                "\n",
                "# Fit softmax classifier\n",
                "lr_mn = LogisticRegression(multi_class=\"multinomial\")\n",
                "lr_mn.fit(X_train, y_train)\n",
                "\n",
                "print(\"Softmax training accuracy:\", lr_mn.score(X_train, y_train))\n",
                "print(\"Softmax test accuracy    :\", lr_mn.score(X_test, y_test))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Visualizing multi-class logistic regression\n",
                "\n",
                "In this exercise we'll continue with the two types of multi-class\n",
                "logistic regression, but on a toy 2D data set specifically designed to\n",
                "break the one-vs-rest scheme.\n",
                "\n",
                "The data set is loaded into `X_train` and `y_train`. The two logistic\n",
                "regression objects,`lr_mn` and `lr_ovr`, are already instantiated (with\n",
                "`C=100`), fit, and plotted.\n",
                "\n",
                "Notice that `lr_ovr` never predicts the dark blue class… yikes! Let's\n",
                "explore why this happens by plotting one of the binary classifiers that\n",
                "it's using behind the scenes.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Create a new logistic regression object (also with `C=100`) to be used\n",
                "  for binary classification.\n",
                "- Visualize this binary classifier with `plot_classifier`… does it look\n",
                "  reasonable?\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Print training accuracies\n",
                "print(\"Softmax     training accuracy:\", lr_mn.score(X_train, y_train))\n",
                "print(\"One-vs-rest training accuracy:\", lr_ovr.score(X_train, y_train))\n",
                "\n",
                "# Create the binary classifier (class 1 vs. rest)\n",
                "lr_class_1 = LogisticRegression(C=100)\n",
                "lr_class_1.fit(X_train, y_train==1)\n",
                "\n",
                "# Plot the binary classifier (class 1 vs. rest)\n",
                "plot_classifier(X_train, y_train==1, lr_class_1)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### One-vs-rest SVM\n",
                "\n",
                "As motivation for the next and final chapter on support vector machines,\n",
                "we'll repeat the previous exercise with a non-linear SVM. Once again,\n",
                "the data is loaded into `X_train`, `y_train`, `X_test`, and `y_test` .\n",
                "\n",
                "Instead of using `LinearSVC`, we'll now use scikit-learn's `SVC` object,\n",
                "which is a non-linear \"kernel\" SVM (much more on what this means in\n",
                "Chapter 4!). Again, your task is to create a plot of the binary\n",
                "classifier for class 1 vs. rest.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Fit an `SVC` called `svm_class_1` to predict class 1 vs. other\n",
                "  classes.\n",
                "- Plot this classifier.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# We'll use SVC instead of LinearSVC from now on\n",
                "from sklearn.svm import SVC\n",
                "\n",
                "# Create/plot the binary classifier (class 1 vs. rest)\n",
                "svm_class_1 = SVC()\n",
                "svm_class_1.fit(X_train, y_train==1)\n",
                "plot_classifier(X_train, y_train==1, svm_class_1)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Support Vector Machines\n",
                "\n",
                "### Effect of removing examples\n",
                "\n",
                "Support vectors are defined as training examples that influence the\n",
                "decision boundary. In this exercise, you'll observe this behavior by\n",
                "removing non support vectors from the training set.\n",
                "\n",
                "The wine quality dataset is already loaded into `X` and `y` (first two\n",
                "features only). (Note: we specify `lims` in `plot_classifier()` so that\n",
                "the two plots are forced to use the same axis limits and can be compared\n",
                "directly.)\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Train a linear SVM on the whole data set.\n",
                "- Create a new data set containing only the support vectors.\n",
                "- Train a new linear SVM on the smaller data set.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train a linear SVM\n",
                "svm = SVC(kernel=\"linear\")\n",
                "svm.fit(X,y)\n",
                "plot_classifier(X, y, svm, lims=(11,15,0,6))\n",
                "\n",
                "# Make a new data set keeping only the support vectors\n",
                "print(\"Number of original examples\", len(X))\n",
                "print(\"Number of support vectors\", len(svm.support_))\n",
                "X_small = X[svm.support_]\n",
                "y_small = y[svm.support_]\n",
                "\n",
                "# Train a new SVM using only the support vectors\n",
                "svm_small = SVC(kernel=\"linear\")\n",
                "svm_small.fit(X_small, y_small)\n",
                "plot_classifier(X_small, y_small, svm_small, lims=(11,15,0,6))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### GridSearchCV warm-up\n",
                "\n",
                "In the video we saw that increasing the RBF kernel hyperparameter\n",
                "`gamma` increases training accuracy. In this exercise we'll search for\n",
                "the `gamma` that maximizes cross-validation accuracy using\n",
                "scikit-learn's `GridSearchCV`. A binary version of the handwritten\n",
                "digits dataset, in which you're just trying to predict whether or not an\n",
                "image is a \"2\", is already loaded into the variables `X` and `y`.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Create a `GridSearchCV` object.\n",
                "- Call the `fit()` method to select the best value of `gamma` based on\n",
                "  cross-validation accuracy.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Instantiate an RBF SVM\n",
                "svm = SVC()\n",
                "\n",
                "# Instantiate the GridSearchCV object and run the search\n",
                "parameters = {'gamma':[0.00001, 0.0001, 0.001, 0.01, 0.1]}\n",
                "searcher = GridSearchCV(svm, parameters)\n",
                "searcher.fit(X, y)\n",
                "\n",
                "# Report the best parameters\n",
                "print(\"Best CV params\", searcher.best_params_)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Jointly tuning gamma and C with GridSearchCV\n",
                "\n",
                "In the previous exercise the best value of `gamma` was 0.001 using the\n",
                "default value of `C`, which is 1. In this exercise you'll search for the\n",
                "best combination of `C` and `gamma` using `GridSearchCV`.\n",
                "\n",
                "As in the previous exercise, the 2-vs-not-2 digits dataset is already\n",
                "loaded, but this time it's split into the variables `X_train`,\n",
                "`y_train`, `X_test`, and `y_test`. Even though cross-validation already\n",
                "splits the training set into parts, it's often a good idea to hold out a\n",
                "separate test set to make sure the cross-validation results are\n",
                "sensible.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Run `GridSearchCV` to find the best hyperparameters using the training\n",
                "  set.\n",
                "- Print the best values of the parameters.\n",
                "- Print out the accuracy on the test set, which was not used during the\n",
                "  cross-validation procedure.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Instantiate an RBF SVM\n",
                "svm = SVC()\n",
                "\n",
                "# Instantiate the GridSearchCV object and run the search\n",
                "parameters = {'C':[0.1, 1, 10], 'gamma':[0.00001, 0.0001, 0.001, 0.01, 0.1]}\n",
                "searcher = GridSearchCV(svm, parameters)\n",
                "searcher.fit(X_train, y_train)\n",
                "\n",
                "# Report the best parameters and the corresponding score\n",
                "print(\"Best CV params\", searcher.best_params_)\n",
                "print(\"Best CV accuracy\", searcher.best_score_)\n",
                "\n",
                "# Report the test accuracy using these best parameters\n",
                "print(\"Test accuracy of best grid search hypers:\", searcher.score(X_test, y_test))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Using SGDClassifier\n",
                "\n",
                "In this final coding exercise, you'll do a hyperparameter search over\n",
                "the regularization strength and the loss (logistic regression vs. linear\n",
                "SVM) using `SGDClassifier()`.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Instantiate an `SGDClassifier` instance with `random_state=0`.\n",
                "- Search over the regularization strength and the `hinge` vs. `log_loss`\n",
                "  losses.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# We set random_state=0 for reproducibility \n",
                "linear_classifier = SGDClassifier(random_state=0)\n",
                "\n",
                "# Instantiate the GridSearchCV object and run the search\n",
                "parameters = {'alpha':[0.00001, 0.0001, 0.001, 0.01, 0.1, 1], \n",
                "             'loss':['hinge', 'log_loss']}\n",
                "searcher = GridSearchCV(linear_classifier, parameters, cv=10)\n",
                "searcher.fit(X_train, y_train)\n",
                "\n",
                "# Report the best parameters and the corresponding score\n",
                "print(\"Best CV params\", searcher.best_params_)\n",
                "print(\"Best CV accuracy\", searcher.best_score_)\n",
                "print(\"Test accuracy of best grid search hypers:\", searcher.score(X_test, y_test))\n"
            ]
        }
    ],
    "metadata": {
        "anaconda-cloud": "",
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
